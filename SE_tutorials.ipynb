{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRN_SE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Or2ADw_Pf6eF",
        "xFcCvs4TqTLI",
        "BFDBtQxonGHk",
        "rEOtu8Fsn0Wa",
        "zY_EN6pdnv1G",
        "8dr6psVdoMPJ",
        "t-608O_vONfP",
        "d3CmmLgnoOpz",
        "pDKYZuA-oSgZ",
        "CJZFyj_toVbj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or2ADw_Pf6eF"
      },
      "source": [
        "# Licence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbAI2-fUf8UC"
      },
      "source": [
        "https://github.com/seorim0/Speech_enhancement_with_Pytorch\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2021 seorim0\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcCvs4TqTLI"
      },
      "source": [
        "# Requirement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P2MGVfaPt9B",
        "outputId": "af63fb4b-6dd2-495c-83bd-2af46e092563"
      },
      "source": [
        "# # For additional installation of libraries not included in the colab main library\n",
        "# !pip install \"library_name\"\n",
        "!pip install pesq\n",
        "!pip install pystoi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pesq in /usr/local/lib/python3.7/dist-packages (0.0.3)\n",
            "Collecting pystoi\n",
            "  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pystoi) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pystoi) (1.4.1)\n",
            "Building wheels for collected packages: pystoi\n",
            "  Building wheel for pystoi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7793 sha256=4b3f5991ad63a316047c2ab9f983f4f7216a7f059fc75df4c0335555ec164e4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/4a/ad/3ab460193ed0535430b4b1575f255aa6bae69df17453628e86\n",
            "Successfully built pystoi\n",
            "Installing collected packages: pystoi\n",
            "Successfully installed pystoi-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTpjvFJwsbPn"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import shutil\n",
        "import logging\n",
        "import numpy as np\n",
        "from pesq import pesq\n",
        "import torch.nn as nn\n",
        "from pystoi import stoi\n",
        "from scipy import interpolate\n",
        "import matplotlib.pylab as plt\n",
        "import scipy.io.wavfile as wav\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from scipy.signal import get_window\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFDBtQxonGHk"
      },
      "source": [
        "# config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci1GVuiPnB4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a419689-3393-4fe2-ec74-c5dc689831ad"
      },
      "source": [
        "\"\"\"\n",
        "Configuration for train_interface\n",
        "\n",
        "You can check the essential information,\n",
        "and if you want to change model structure or training method,\n",
        "you have to change this file.\n",
        "\"\"\"\n",
        "#######################################################################\n",
        "#                                 path                                #\n",
        "#######################################################################\n",
        "job_dir = './'  # 'FILE PATH for saving models' \n",
        "chkpt_model = None  # 'FILE PATH (if you have pretrained model..)'\n",
        "chkpt = str(\"EPOCH\")  \n",
        "if chkpt_model is not None:\n",
        "    chkpt_path = job_dir + chkpt_model + '/chkpt_' + chkpt + '.pt'\n",
        "\n",
        "#######################################################################\n",
        "#                         possible setting                            #\n",
        "#######################################################################\n",
        "# the list you can do\n",
        "model_list = ['CRN']\n",
        "loss_list = ['MSE', 'SDR', 'SI-SNR', 'SI-SDR']\n",
        "mask_type = ['Direct(None make)', 'E', 'C', 'R']\n",
        "window_type = ['hanning']\n",
        "\n",
        "# experiment number setting\n",
        "expr_num = 'EXPERIMENT_NUMBER'\n",
        "DEVICE = 'cuda'  # if you want to run the code with 'cpu', change 'cpu'\n",
        "#######################################################################\n",
        "#                           current setting                           #\n",
        "#######################################################################\n",
        "current_model = model_list[0]\n",
        "current_loss = loss_list[0]\n",
        "\n",
        "masking_mode = mask_type[1]\n",
        "window = window_type[0]\n",
        "skip_type = True   # False, if you want to remove 'skip connection'\n",
        "direct_mapping = True if masking_mode == 'Direct(None make)'else False\n",
        "\n",
        "# hyper-parameters\n",
        "max_epochs = 100\n",
        "learning_rate = 0.001\n",
        "batch = 10\n",
        "\n",
        "# kernel size\n",
        "dccrn_kernel_num = [32, 64, 128, 256, 256, 256]\n",
        "#######################################################################\n",
        "#                         model information                           #\n",
        "#######################################################################\n",
        "fs = 16000\n",
        "win_len = 400\n",
        "win_inc = 100\n",
        "ola_ratio = win_inc / win_len\n",
        "fft_len = 512 #2048 #512\n",
        "sam_sec = fft_len / fs\n",
        "frm_samp = fs * (fft_len / fs)\n",
        "\n",
        "rnn_layers = 2\n",
        "rnn_input_size = 640 \n",
        "rnn_units = 128\n",
        "#######################################################################\n",
        "#                      setting error check                            #\n",
        "#######################################################################\n",
        "# if the setting is wrong, print error message\n",
        "\n",
        "#######################################################################\n",
        "#                           print setting                             #\n",
        "#######################################################################\n",
        "print('--------------------  C  O  N  F  I  G  ----------------------')\n",
        "print('--------------------------------------------------------------')\n",
        "print('MODEL INFO : {}'.format(current_model))\n",
        "print('LOSS INFO : {}'.format(current_loss))\n",
        "print('SKIP : {}'.format(skip_type))\n",
        "print('MASKING INFO : {}'.format(masking_mode))\n",
        "print('\\nBATCH : {}'.format(batch))\n",
        "print('LEARNING RATE : {}'.format(learning_rate))\n",
        "print('--------------------------------------------------------------')\n",
        "print('--------------------------------------------------------------\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------  C  O  N  F  I  G  ----------------------\n",
            "--------------------------------------------------------------\n",
            "MODEL INFO : CRN\n",
            "LOSS INFO : SDR\n",
            "SKIP : True\n",
            "MASKING INFO : E\n",
            "\n",
            "BATCH : 10\n",
            "LEARNING RATE : 0.001\n",
            "--------------------------------------------------------------\n",
            "--------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEOtu8Fsn0Wa"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7BnscOrn3CY"
      },
      "source": [
        "def create_dataloader(mode, type=0, snr=0):\n",
        "    if mode == 'train':\n",
        "        return DataLoader(\n",
        "            dataset=Wave_Dataset(mode, type, snr),\n",
        "            batch_size=batch,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True,\n",
        "            drop_last=True,\n",
        "            sampler=None\n",
        "        )\n",
        "    elif mode == 'valid':\n",
        "        return DataLoader(\n",
        "            dataset=Wave_Dataset(mode, type, snr),\n",
        "            batch_size=batch, shuffle=False, num_workers=0\n",
        "        )\n",
        "\n",
        "class Wave_Dataset(Dataset):\n",
        "    def __init__(self, mode, type, snr):\n",
        "        # load data\n",
        "        if mode == 'train':\n",
        "            self.mode = 'train'\n",
        "            print('<Training dataset>')\n",
        "            print('Load the data...')\n",
        "            self.input = np.ones((300, 2, 16000))\n",
        "            # self.input_path = \"\"DATASET_FILE_PATH\"\"\n",
        "            # self.input = np.load(self.input_path)\n",
        "        elif mode == 'valid':\n",
        "            self.mode = 'valid'\n",
        "            print('<Validation dataset>')\n",
        "            print('Load the data...')\n",
        "            self.input = np.ones((50, 2, 16000))\n",
        "            # self.input_path = \"\"DATASET_FILE_PATH\"\"\n",
        "            # self.input = np.load(self.input_path)\n",
        "            # # if you want to use a part of the dataset\n",
        "            # self.input = self.input[:500]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "            inputs = self.input[idx][0]\n",
        "            targets = self.input[idx][1]\n",
        "\n",
        "            # transform to torch from numpy\n",
        "            inputs = torch.from_numpy(inputs)\n",
        "            targets = torch.from_numpy(targets)\n",
        "\n",
        "            return inputs, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY_EN6pdnv1G"
      },
      "source": [
        "# Tools for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qhcrPGhoLKJ"
      },
      "source": [
        "############################################################################\n",
        "#                         for convolutional STFT                           #\n",
        "############################################################################\n",
        "# this is from conv_stft https://github.com/huyanxin/DeepComplexCRN\n",
        "def init_kernels(win_len, win_inc, fft_len, win_type=None, invers=False):\n",
        "    if win_type == 'None' or win_type is None:\n",
        "        window = np.ones(win_len)\n",
        "    else:\n",
        "        window = get_window(win_type, win_len, fftbins=True)  # **0.5\n",
        "\n",
        "    N = fft_len\n",
        "    fourier_basis = np.fft.rfft(np.eye(N))[:win_len]\n",
        "    real_kernel = np.real(fourier_basis)\n",
        "    imag_kernel = np.imag(fourier_basis)\n",
        "    kernel = np.concatenate([real_kernel, imag_kernel], 1).T\n",
        "\n",
        "    if invers:\n",
        "        kernel = np.linalg.pinv(kernel).T\n",
        "\n",
        "    kernel = kernel * window\n",
        "    kernel = kernel[:, None, :]\n",
        "    return torch.from_numpy(kernel.astype(np.float32)), torch.from_numpy(window[None, :, None].astype(np.float32))\n",
        "\n",
        "\n",
        "class ConvSTFT(nn.Module):\n",
        "\n",
        "    def __init__(self, win_len, win_inc, fft_len=None, win_type='hamming', feature_type='real', fix=True):\n",
        "        super(ConvSTFT, self).__init__()\n",
        "\n",
        "        if fft_len == None:\n",
        "            self.fft_len = np.int(2 ** np.ceil(np.log2(win_len)))\n",
        "        else:\n",
        "            self.fft_len = fft_len\n",
        "\n",
        "        kernel, _ = init_kernels(win_len, win_inc, self.fft_len, win_type)\n",
        "        # self.weight = nn.Parameter(kernel, requires_grad=(not fix))\n",
        "        self.register_buffer('weight', kernel)\n",
        "        self.feature_type = feature_type\n",
        "        self.stride = win_inc\n",
        "        self.win_len = win_len\n",
        "        self.dim = self.fft_len\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if inputs.dim() == 2:\n",
        "            inputs = torch.unsqueeze(inputs, 1)\n",
        "        inputs = F.pad(inputs, [self.win_len - self.stride, self.win_len - self.stride])\n",
        "        outputs = F.conv1d(inputs, self.weight, stride=self.stride)\n",
        "\n",
        "        if self.feature_type == 'complex':\n",
        "            return outputs\n",
        "        else:\n",
        "            dim = self.dim // 2 + 1\n",
        "            real = outputs[:, :dim, :]\n",
        "            imag = outputs[:, dim:, :]\n",
        "            mags = torch.sqrt(real ** 2 + imag ** 2)\n",
        "            phase = torch.atan2(imag, real)\n",
        "            return mags, phase\n",
        "\n",
        "\n",
        "class ConviSTFT(nn.Module):\n",
        "\n",
        "    def __init__(self, win_len, win_inc, fft_len=None, win_type='hamming', feature_type='real', fix=True):\n",
        "        super(ConviSTFT, self).__init__()\n",
        "        if fft_len == None:\n",
        "            self.fft_len = np.int(2 ** np.ceil(np.log2(win_len)))\n",
        "        else:\n",
        "            self.fft_len = fft_len\n",
        "        kernel, window = init_kernels(win_len, win_inc, self.fft_len, win_type, invers=True)\n",
        "        # self.weight = nn.Parameter(kernel, requires_grad=(not fix))\n",
        "        self.register_buffer('weight', kernel)\n",
        "        self.feature_type = feature_type\n",
        "        self.win_type = win_type\n",
        "        self.win_len = win_len\n",
        "        self.stride = win_inc\n",
        "        self.dim = self.fft_len\n",
        "        self.register_buffer('window', window)\n",
        "        self.register_buffer('enframe', torch.eye(win_len)[:, None, :])\n",
        "\n",
        "    def forward(self, inputs, phase=None):\n",
        "        \"\"\"\n",
        "        inputs : [B, N+2, T] (complex spec) or [B, N//2+1, T] (mags)\n",
        "        phase: [B, N//2+1, T] (if not none)\n",
        "        \"\"\"\n",
        "\n",
        "        if phase is not None:\n",
        "            real = inputs * torch.cos(phase)\n",
        "            imag = inputs * torch.sin(phase)\n",
        "            inputs = torch.cat([real, imag], 1)\n",
        "\n",
        "        outputs = F.conv_transpose1d(inputs, self.weight, stride=self.stride)\n",
        "\n",
        "        # this is from torch-stft: https://github.com/pseeth/torch-stft\n",
        "        t = self.window.repeat(1, 1, inputs.size(-1)) ** 2\n",
        "        coff = F.conv_transpose1d(t, self.enframe, stride=self.stride)\n",
        "\n",
        "        outputs = outputs / (coff + 1e-8)\n",
        "\n",
        "        outputs = outputs[..., self.win_len - self.stride:-(self.win_len - self.stride)]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "############################################################################\n",
        "#                             for complex rnn                              #\n",
        "############################################################################\n",
        "def get_casual_padding1d():\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_casual_padding2d():\n",
        "    pass\n",
        "\n",
        "\n",
        "class cPReLU(nn.Module):\n",
        "\n",
        "    def __init__(self, complex_axis=1):\n",
        "        super(cPReLU, self).__init__()\n",
        "        self.r_prelu = nn.PReLU()\n",
        "        self.i_prelu = nn.PReLU()\n",
        "        self.complex_axis = complex_axis\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        real, imag = torch.chunk(inputs, 2, self.complex_axis)\n",
        "        real = self.r_prelu(real)\n",
        "        imag = self.i_prelu(imag)\n",
        "        return torch.cat([real, imag], self.complex_axis)\n",
        "\n",
        "\n",
        "############################################################################\n",
        "#                         for data normalization                           #\n",
        "############################################################################\n",
        "class RealConv2d(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=(1, 1),\n",
        "            stride=(1, 1),\n",
        "            padding=(0, 0),\n",
        "            dilation=1,\n",
        "            groups=1,\n",
        "            causal=True,\n",
        "            complex_axis=1,\n",
        "    ):\n",
        "        '''\n",
        "            in_channels: real+imag\n",
        "            out_channels: real+imag\n",
        "            kernel_size : input [B,C,D,T] kernel size in [D,T]\n",
        "            padding : input [B,C,D,T] padding in [D,T]\n",
        "            causal: if causal, will padding time dimension's left side,\n",
        "                    otherwise both\n",
        "\n",
        "        '''\n",
        "        super(RealConv2d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.causal = causal\n",
        "        self.groups = groups\n",
        "        self.dilation = dilation\n",
        "\n",
        "        self.conv = nn.Conv2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
        "                                   padding=[self.padding[0], 0], dilation=self.dilation, groups=self.groups)\n",
        "\n",
        "        nn.init.normal_(self.conv.weight.data, std=0.05)\n",
        "        nn.init.constant_(self.conv.bias, 0.)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.padding[1] != 0 and self.causal:\n",
        "            inputs = F.pad(inputs, [self.padding[1], 0, 0, 0])  ## [width left, width right, height left, height right]\n",
        "        else:\n",
        "            inputs = F.pad(inputs, [self.padding[1], self.padding[1], 0, 0])\n",
        "\n",
        "        out = self.conv(inputs)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class RealConvTranspose2d(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=(1, 1),\n",
        "            stride=(1, 1),\n",
        "            padding=(0, 0),\n",
        "            output_padding=(0, 0),\n",
        "            groups=1\n",
        "    ):\n",
        "        '''\n",
        "            in_channels: real+imag\n",
        "            out_channels: real+imag\n",
        "        '''\n",
        "        super(RealConvTranspose2d, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.output_padding = output_padding\n",
        "        self.groups = groups\n",
        "\n",
        "        self.conv = nn.ConvTranspose2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
        "                                            padding=self.padding, output_padding=output_padding, groups=self.groups)\n",
        "\n",
        "        nn.init.normal_(self.conv.weight.data, std=0.05)\n",
        "        nn.init.constant_(self.conv.bias, 0.)\n",
        "\n",
        "        # # weight standardization\n",
        "        # self.real_conv = ConvTranspose2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
        "        #                                     padding=self.padding, output_padding=output_padding, groups=self.groups)\n",
        "        # self.imag_conv = ConvTranspose2d(self.in_channels, self.out_channels, kernel_size, self.stride,\n",
        "        #                                     padding=self.padding, output_padding=output_padding, groups=self.groups)\n",
        "        # self.complex_axis = complex_axis\n",
        "        #\n",
        "        # nn.init.constant_(self.real_conv.bias, 0.)\n",
        "        # nn.init.constant_(self.imag_conv.bias, 0.)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        out = self.conv(inputs)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "############################################################################\n",
        "#                         for data normalization                           #\n",
        "############################################################################\n",
        "# get mu and sig\n",
        "def get_mu_sig(data):\n",
        "    \"\"\"Compute mean and standard deviation vector of input data\n",
        "\n",
        "    Returns:\n",
        "        mu: mean vector (#dim by one)\n",
        "        sig: standard deviation vector (#dim by one)\n",
        "    \"\"\"\n",
        "    # Initialize array.\n",
        "    data_num = len(data)\n",
        "    mu_utt = []\n",
        "    tmp_utt = []\n",
        "    for n in range(data_num):\n",
        "        dim = len(data[n])\n",
        "        mu_utt_tmp = np.zeros(dim)\n",
        "        mu_utt.append(mu_utt_tmp)\n",
        "\n",
        "        tmp_utt_tmp = np.zeros(dim)\n",
        "        tmp_utt.append(tmp_utt_tmp)\n",
        "\n",
        "    # Get mean.\n",
        "    for n in range(data_num):\n",
        "        mu_utt[n] = np.mean(data[n], 0)\n",
        "    mu = mu_utt\n",
        "\n",
        "    # Get standard deviation.\n",
        "    for n in range(data_num):\n",
        "        tmp_utt[n] = np.mean(np.square(data[n] - mu[n]), 0)\n",
        "    sig = np.sqrt(tmp_utt)\n",
        "\n",
        "    # Assign unit variance.\n",
        "    for n in range(len(sig)):\n",
        "        if sig[n] < 1e-5:\n",
        "            sig[n] = 1.0\n",
        "    return np.float16(mu), np.float16(sig)\n",
        "\n",
        "\n",
        "def get_statistics_inp(inp):\n",
        "    \"\"\"Get statistical parameter of input data.\n",
        "\n",
        "    Args:\n",
        "        inp: input data\n",
        "\n",
        "    Returns:\n",
        "        mu_inp: mean vector of input data\n",
        "        sig_inp: standard deviation vector of input data\n",
        "    \"\"\"\n",
        "\n",
        "    mu_inp, sig_inp = get_mu_sig(inp)\n",
        "\n",
        "    return mu_inp, sig_inp\n",
        "\n",
        "\n",
        "# normalize [-1 1]\n",
        "def normalize_dataset(dataset):\n",
        "    for i in range(len(dataset)):\n",
        "            noisy_max = np.max(abs(dataset[i][0]))\n",
        "            dataset[i][0] = dataset[i][0] / noisy_max\n",
        "\n",
        "            clean_max = np.max(abs(dataset[i][1]))\n",
        "            dataset[i][1] = dataset[i][1] / clean_max\n",
        "    return dataset\n",
        "\n",
        "\n",
        "############################################################################\n",
        "#                       for plotting the samples                           #\n",
        "############################################################################\n",
        "def hann_window(win_samp):\n",
        "    tmp = np.arange(1, win_samp + 1, 1.0, dtype=np.float64)\n",
        "    window = 0.5 - 0.5 * np.cos((2.0 * np.pi * tmp) / (win_samp + 1))\n",
        "    return np.float32(window)\n",
        "\n",
        "\n",
        "def fig2np(fig):\n",
        "    data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "    return data\n",
        "\n",
        "\n",
        "def plot_spectrogram_to_numpy(input_wav, fs, n_fft, n_overlap, win, mode, clim, label):\n",
        "    # cuda to cpu\n",
        "    input_wav = input_wav.cpu().detach().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 3))\n",
        "\n",
        "    if mode == 'phase':\n",
        "        pxx, freq, t, cax = plt.specgram(input_wav, NFFT=int(n_fft), Fs=int(fs), window=win, noverlap=n_overlap,\n",
        "                                         cmap='jet',\n",
        "                                         mode=mode)\n",
        "    else:\n",
        "        pxx, freq, t, cax = plt.specgram(input_wav, NFFT=int(n_fft), Fs=int(fs), window=win, noverlap=n_overlap,\n",
        "                                         cmap='jet')\n",
        "\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Frequency (Hz)')\n",
        "    plt.tight_layout()\n",
        "    plt.clim(clim)\n",
        "\n",
        "    if label is None:\n",
        "        fig.colorbar(cax)\n",
        "    else:\n",
        "        fig.colorbar(cax, label=label)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    data = fig2np(fig)\n",
        "    plt.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "def plot_mask_to_numpy(mask, fs, n_fft, n_overlap, win, clim1, clim2, cmap):\n",
        "    frame_num = mask.shape[0]\n",
        "    shift_length = n_overlap\n",
        "    frame_length = n_fft\n",
        "    signal_length = frame_num * shift_length + frame_length\n",
        "\n",
        "    xt = np.arange(0, np.floor(10 * signal_length / fs) / 10, step=0.5) / (signal_length / fs) * frame_num + 1e-8\n",
        "    yt = (n_fft / 2) / (fs / 1000 / 2) * np.arange(0, (fs / 1000 / 2) + 1)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 3))\n",
        "    im = ax.imshow(np.transpose(mask), aspect='auto', origin='lower', interpolation='none', cmap=cmap)\n",
        "\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Frequency (kHz)')\n",
        "    plt.xticks(xt, np.arange(0, np.floor(10 * (signal_length / fs)) / 10, step=0.5))\n",
        "    plt.yticks(yt, np.int16(np.linspace(0, int((fs / 1000) / 2), len(yt))))\n",
        "    plt.tight_layout()\n",
        "    plt.colorbar(im, ax=ax)\n",
        "    im.set_clim(clim1, clim2)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    data = fig2np(fig)\n",
        "    plt.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "def plot_error_to_numpy(estimated, target, fs, n_fft, n_overlap, win, mode, clim1, clim2, label):\n",
        "    fig, ax = plt.subplots(figsize=(12, 3))\n",
        "    if mode == None:\n",
        "        pxx1, freq, t, cax = plt.specgram(estimated, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet')\n",
        "        pxx2, freq, t, cax = plt.specgram(target, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet')\n",
        "        im = ax.imshow(10 * np.log10(pxx1) - 10 * np.log10(pxx2), aspect='auto', origin='lower', interpolation='none',\n",
        "                       cmap='jet')\n",
        "    else:\n",
        "        pxx1, freq, t, cax = plt.specgram(estimated, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet',\n",
        "                                          mode=mode)\n",
        "        pxx2, freq, t, cax = plt.specgram(target, NFFT=n_fft, Fs=int(fs), window=win, noverlap=n_overlap, cmap='jet',\n",
        "                                          mode=mode)\n",
        "        im = ax.imshow(pxx1 - pxx2, aspect='auto', origin='lower', interpolation='none', cmap='jet')\n",
        "\n",
        "    frame_num = pxx1.shape[1]\n",
        "    shift_length = n_overlap\n",
        "    frame_length = n_fft\n",
        "    signal_length = frame_num * shift_length + frame_length\n",
        "\n",
        "    xt = np.arange(0, np.floor(10 * (signal_length / fs)) / 10, step=0.5) / (signal_length / fs) * frame_num\n",
        "    yt = (n_fft / 2) / (fs / 1000 / 2) * np.arange(0, (fs / 1000 / 2) + 1)\n",
        "\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Frequency (kHz)')\n",
        "    plt.xticks(xt, np.arange(0, np.floor(10 * (signal_length / fs)) / 10, step=0.5))\n",
        "    plt.yticks(yt, np.int16(np.linspace(0, int((fs / 1000) / 2), len(yt))))\n",
        "    plt.tight_layout()\n",
        "    plt.colorbar(im, ax=ax, label=label)\n",
        "    im.set_clim(clim1, clim2)\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    data = fig2np(fig)\n",
        "    plt.close()\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "############################################################################\n",
        "#                                for run.py                                #\n",
        "############################################################################\n",
        "def near_avg_index(array):\n",
        "    array_mean = np.mean(array)\n",
        "\n",
        "    distance_arr = []\n",
        "    for i in range(len(array)):\n",
        "        val = array[i]\n",
        "        distance = abs(array_mean - val)\n",
        "        distance_arr.append(distance)\n",
        "\n",
        "    index = distance_arr.index(min(distance_arr))\n",
        "    return index\n",
        "\n",
        "\n",
        "def max_index(array):\n",
        "    array_max = np.max(array)\n",
        "\n",
        "    for i in range(len(array)):\n",
        "        val = array[i]\n",
        "        if val == array_max:\n",
        "            index = i\n",
        "    return index\n",
        "\n",
        "\n",
        "def min_index(array):\n",
        "    array_min = np.min(array)\n",
        "\n",
        "    for i in range(len(array)):\n",
        "        val = array[i]\n",
        "        if val == array_min:\n",
        "            index = i\n",
        "    return index\n",
        "\n",
        "\n",
        "class Bar(object):\n",
        "    def __init__(self, dataloader):\n",
        "        if not hasattr(dataloader, 'dataset'):\n",
        "            raise ValueError('Attribute `dataset` not exists in dataloder.')\n",
        "        if not hasattr(dataloader, 'batch_size'):\n",
        "            raise ValueError('Attribute `batch_size` not exists in dataloder.')\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "        self.iterator = iter(dataloader)\n",
        "        self.dataset = dataloader.dataset\n",
        "        self.batch_size = dataloader.batch_size\n",
        "        self._idx = 0\n",
        "        self._batch_idx = 0\n",
        "        self._time = []\n",
        "        self._DISPLAY_LENGTH = 50\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataloader)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if len(self._time) < 2:\n",
        "            self._time.append(time.time())\n",
        "\n",
        "        self._batch_idx += self.batch_size\n",
        "        if self._batch_idx > len(self.dataset):\n",
        "            self._batch_idx = len(self.dataset)\n",
        "\n",
        "        try:\n",
        "            batch = next(self.iterator)\n",
        "            self._display()\n",
        "        except StopIteration:\n",
        "            raise StopIteration()\n",
        "\n",
        "        self._idx += 1\n",
        "        if self._idx >= len(self.dataloader):\n",
        "            self._reset()\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def _display(self):\n",
        "        if len(self._time) > 1:\n",
        "            t = (self._time[-1] - self._time[-2])\n",
        "            eta = t * (len(self.dataloader) - self._idx)\n",
        "        else:\n",
        "            eta = 0\n",
        "\n",
        "        rate = self._idx / len(self.dataloader)\n",
        "        len_bar = int(rate * self._DISPLAY_LENGTH)\n",
        "        bar = ('=' * len_bar + '>').ljust(self._DISPLAY_LENGTH, '.')\n",
        "        idx = str(self._batch_idx).rjust(len(str(len(self.dataset))), ' ')\n",
        "\n",
        "        tmpl = '\\r{}/{}: [{}] - ETA {:.1f}s'.format(\n",
        "            idx,\n",
        "            len(self.dataset),\n",
        "            bar,\n",
        "            eta\n",
        "        )\n",
        "        print(tmpl, end='')\n",
        "        if self._batch_idx == len(self.dataset):\n",
        "            print()\n",
        "\n",
        "    def _reset(self):\n",
        "        self._idx = 0\n",
        "        self._batch_idx = 0\n",
        "        self._time = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dr6psVdoMPJ"
      },
      "source": [
        "# Tools for loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4xPWf8ToOYf"
      },
      "source": [
        "############################################################################\n",
        "#               for model structure & loss function                        #\n",
        "############################################################################\n",
        "def remove_dc(data):\n",
        "    mean = torch.mean(data, -1, keepdim=True)\n",
        "    data = data - mean\n",
        "    return data\n",
        "\n",
        "\n",
        "def l2_norm(s1, s2):\n",
        "    # norm = torch.sqrt(torch.sum(s1*s2, 1, keepdim=True))\n",
        "    # norm = torch.norm(s1*s2, 1, keepdim=True)\n",
        "\n",
        "    norm = torch.sum(s1 * s2, -1, keepdim=True)\n",
        "    return norm\n",
        "\n",
        "\n",
        "def sdr(s1, s2, eps=1e-8):\n",
        "    sn = l2_norm(s1, s1)\n",
        "    sn_m_shn = l2_norm(s1 - s2, s1 - s2)\n",
        "    sdr_loss = 10 * torch.log10(sn**2 / (sn_m_shn**2 + eps))\n",
        "    return torch.mean(sdr_loss)\n",
        "\n",
        "\n",
        "def si_snr(s1, s2, eps=1e-8):\n",
        "    # s1 = remove_dc(s1)\n",
        "    # s2 = remove_dc(s2)\n",
        "    s1_s2_norm = l2_norm(s1, s2)\n",
        "    s2_s2_norm = l2_norm(s2, s2)\n",
        "    s_target = s1_s2_norm / (s2_s2_norm + eps) * s2\n",
        "    e_nosie = s1 - s_target\n",
        "    target_norm = l2_norm(s_target, s_target)\n",
        "    noise_norm = l2_norm(e_nosie, e_nosie)\n",
        "    snr = 10 * torch.log10((target_norm) / (noise_norm + eps) + eps)\n",
        "    return torch.mean(snr)\n",
        "\n",
        "\n",
        "def si_sdr(reference, estimation, eps=1e-8):\n",
        "    \"\"\"\n",
        "        Scale-Invariant Signal-to-Distortion Ratio (SI-SDR)\n",
        "        Args:\n",
        "            reference: numpy.ndarray, [..., T]\n",
        "            estimation: numpy.ndarray, [..., T]\n",
        "        Returns:\n",
        "            SI-SDR\n",
        "        [1] SDRâ€“ Half- Baked or Well Done?\n",
        "        http://www.merl.com/publications/docs/TR2019-013.pdf\n",
        "        >>> np.random.seed(0)\n",
        "        >>> reference = np.random.randn(100)\n",
        "        >>> si_sdr(reference, reference)\n",
        "        inf\n",
        "        >>> si_sdr(reference, reference * 2)\n",
        "        inf\n",
        "        >>> si_sdr(reference, np.flip(reference))\n",
        "        -25.127672346460717\n",
        "        >>> si_sdr(reference, reference + np.flip(reference))\n",
        "        0.481070445785553\n",
        "        >>> si_sdr(reference, reference + 0.5)\n",
        "        6.3704606032577304\n",
        "        >>> si_sdr(reference, reference * 2 + 1)\n",
        "        6.3704606032577304\n",
        "        >>> si_sdr([1., 0], [0., 0])  # never predict only zeros\n",
        "        nan\n",
        "        >>> si_sdr([reference, reference], [reference * 2 + 1, reference * 1 + 0.5])\n",
        "        array([6.3704606, 6.3704606])\n",
        "        :param reference:\n",
        "        :param estimation:\n",
        "        :param eps:\n",
        "        \"\"\"\n",
        "\n",
        "    reference_energy = torch.sum(reference ** 2, axis=-1, keepdims=True)\n",
        "\n",
        "    # This is $\\alpha$ after Equation (3) in [1].\n",
        "    optimal_scaling = torch.sum(reference * estimation, axis=-1, keepdims=True) / reference_energy + eps\n",
        "\n",
        "    # This is $e_{\\text{target}}$ in Equation (4) in [1].\n",
        "    projection = optimal_scaling * reference\n",
        "\n",
        "    # This is $e_{\\text{res}}$ in Equation (4) in [1].\n",
        "    noise = estimation - projection\n",
        "\n",
        "    ratio = torch.sum(projection ** 2, axis=-1) / torch.sum(noise ** 2, axis=-1) + eps\n",
        "\n",
        "    ratio = torch.mean(ratio)\n",
        "    return 10 * torch.log10(ratio + eps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-608O_vONfP"
      },
      "source": [
        "# Tools for score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6JamLlgOdNO"
      },
      "source": [
        "###############################################################################\n",
        "#                           PESQ (another ref)                                #\n",
        "###############################################################################\n",
        "# interface to PESQ evaluation, taking in two waveforms as input\n",
        "def cal_pesq(dirty_wavs, clean_wavs):\n",
        "    scores = []\n",
        "    for i in range(len(dirty_wavs)):\n",
        "        pesq_score = pesq(fs, dirty_wavs[i], clean_wavs[i], 'wb')\n",
        "        scores.append(pesq_score)\n",
        "    return scores\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#                                     STOI                                    #\n",
        "###############################################################################\n",
        "def cal_stoi(estimated_speechs, clean_speechs):\n",
        "    stoi_scores = []\n",
        "    for i in range(len(estimated_speechs)):\n",
        "        stoi_score = stoi(clean_speechs[i], estimated_speechs[i], cfg.fs, extended=False)\n",
        "        stoi_scores.append(stoi_score)\n",
        "    return stoi_scores\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#                                     SNR                                     #\n",
        "###############################################################################\n",
        "def cal_snr(s1, s2, eps=1e-8):\n",
        "    signal = s2\n",
        "    mean_signal = np.mean(signal)\n",
        "    signal_diff = signal - mean_signal\n",
        "    var_signal = np.sum(np.mean(signal_diff ** 2))  # # variance of orignal data\n",
        "\n",
        "    noisy_signal = s1\n",
        "    noise = noisy_signal - signal\n",
        "    mean_noise = np.mean(noise)\n",
        "    noise_diff = noise - mean_noise\n",
        "    var_noise = np.sum(np.mean(noise_diff ** 2))  # # variance of noise\n",
        "\n",
        "    if var_noise == 0:\n",
        "        snr_score = 100  # # clean\n",
        "    else:\n",
        "        snr_score = (np.log10(var_signal/var_noise + eps))*10\n",
        "    return snr_score\n",
        "\n",
        "\n",
        "def cal_snr_array(estimated_speechs, clean_speechs):\n",
        "    snr_score = []\n",
        "    for i in range(len(estimated_speechs)):\n",
        "        snr = cal_snr(estimated_speechs[i], clean_speechs[i])\n",
        "        snr_score.append(snr)\n",
        "    return snr_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3CmmLgnoOpz"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lm9RahEoSN1"
      },
      "source": [
        "#######################################################################\n",
        "#                            real network                             #\n",
        "#######################################################################\n",
        "class CRN(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            rnn_layers=rnn_layers,\n",
        "            rnn_units=rnn_units,\n",
        "            win_len=win_len,\n",
        "            win_inc=win_inc,\n",
        "            fft_len=fft_len,\n",
        "            win_type=window,\n",
        "            kernel_size=5\n",
        "    ):\n",
        "        '''\n",
        "            rnn_layers: the number of lstm layers in the crn\n",
        "        '''\n",
        "\n",
        "        super(CRN, self).__init__()\n",
        "\n",
        "        # for fft\n",
        "        self.win_len = win_len\n",
        "        self.win_inc = win_inc\n",
        "        self.fft_len = fft_len\n",
        "        self.win_type = win_type\n",
        "\n",
        "        input_dim = win_len\n",
        "        output_dim = win_len\n",
        "\n",
        "        self.rnn_input_size = rnn_input_size\n",
        "        self.rnn_units = rnn_units\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_layers = rnn_layers\n",
        "        self.kernel_size = kernel_size\n",
        "        kernel_num = dccrn_kernel_num\n",
        "        self.kernel_num = [2] + kernel_num\n",
        "\n",
        "        # bidirectional=True\n",
        "        bidirectional = False\n",
        "        fac = 2 if bidirectional else 1\n",
        "\n",
        "        self.stft = ConvSTFT(self.win_len, self.win_inc, fft_len, self.win_type, 'real')\n",
        "        self.istft = ConviSTFT(self.win_len, self.win_inc, fft_len, self.win_type, 'real')\n",
        "\n",
        "        self.encoder = nn.ModuleList()\n",
        "        self.decoder = nn.ModuleList()\n",
        "        for idx in range(len(self.kernel_num) - 1):\n",
        "            self.encoder.append(\n",
        "                nn.Sequential(\n",
        "                    RealConv2d(\n",
        "                        self.kernel_num[idx]//2,\n",
        "                        self.kernel_num[idx + 1]//2,\n",
        "                        kernel_size=(self.kernel_size, 2),\n",
        "                        stride=(2, 1),\n",
        "                        padding=(2, 1)\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(self.kernel_num[idx + 1]//2),\n",
        "                    nn.PReLU() \n",
        "                )\n",
        "            )\n",
        "        hidden_dim = self.fft_len // (2 ** (len(self.kernel_num)))\n",
        "\n",
        "        self.enhance = nn.LSTM(\n",
        "            input_size=self.rnn_input_size,\n",
        "            hidden_size=self.rnn_units,\n",
        "            dropout=0.0,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=False\n",
        "        )\n",
        "        self.tranform = nn.Linear(self.rnn_units, self.rnn_input_size)\n",
        "\n",
        "        if skip_type:\n",
        "            for idx in range(len(self.kernel_num) - 1, 0, -1):\n",
        "                if idx != 1:\n",
        "                    self.decoder.append(\n",
        "                        nn.Sequential(\n",
        "                            RealConvTranspose2d(\n",
        "                                self.kernel_num[idx],\n",
        "                                self.kernel_num[idx - 1]//2,\n",
        "                                kernel_size=(self.kernel_size, 2),\n",
        "                                stride=(2, 1),\n",
        "                                padding=(2, 0),\n",
        "                                output_padding=(1, 0)\n",
        "                            ),\n",
        "                            nn.BatchNorm2d(self.kernel_num[idx - 1]//2),\n",
        "                            nn.PReLU() \n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    self.decoder.append(\n",
        "                        nn.Sequential(\n",
        "                            RealConvTranspose2d(\n",
        "                                self.kernel_num[idx],\n",
        "                                self.kernel_num[idx - 1]//2,\n",
        "                                kernel_size=(self.kernel_size, 2),\n",
        "                                stride=(2, 1),\n",
        "                                padding=(2, 0),\n",
        "                                output_padding=(1, 0)\n",
        "                            ),\n",
        "                        )\n",
        "                    )\n",
        "        else:\n",
        "            for idx in range(len(self.kernel_num) - 1, 0, -1):\n",
        "                if idx != 1:\n",
        "                    self.decoder.append(\n",
        "                        nn.Sequential(\n",
        "                            nn.ConvTranspose2d(\n",
        "                                self.kernel_num[idx],\n",
        "                                self.kernel_num[idx - 1],\n",
        "                                kernel_size=(self.kernel_size, 2),\n",
        "                                stride=(2, 1),\n",
        "                                padding=(2, 0),\n",
        "                                output_padding=(1, 0)\n",
        "                            ),\n",
        "                            nn.BatchNorm2d(self.kernel_num[idx - 1]),\n",
        "                            # nn.ELU()\n",
        "                            nn.PReLU()\n",
        "                        )\n",
        "                    )\n",
        "                else:\n",
        "                    self.decoder.append(\n",
        "                        nn.Sequential(\n",
        "                            nn.ConvTranspose2d(\n",
        "                                self.kernel_num[idx],\n",
        "                                self.kernel_num[idx - 1],\n",
        "                                kernel_size=(self.kernel_size, 2),\n",
        "                                stride=(2, 1),\n",
        "                                padding=(2, 0),\n",
        "                                output_padding=(1, 0)\n",
        "                            ),\n",
        "                        )\n",
        "                    )\n",
        "        self.flatten_parameters()\n",
        "\n",
        "    def flatten_parameters(self):\n",
        "        if isinstance(self.enhance, nn.LSTM):\n",
        "            self.enhance.flatten_parameters()\n",
        "\n",
        "    def forward(self, inputs, targets=0):\n",
        "\n",
        "        mags, phase = self.stft(inputs)\n",
        "\n",
        "        out = mags\n",
        "        out = out.unsqueeze(1)\n",
        "        encoder_out = []\n",
        "\n",
        "        for idx, layer in enumerate(self.encoder):\n",
        "            out = layer(out)\n",
        "            #    print('encoder', out.size())\n",
        "            encoder_out.append(out)\n",
        "\n",
        "        batch_size, channels, dims, lengths = out.size()\n",
        "        out = out.permute(3, 0, 1, 2)\n",
        "\n",
        "        rnn_in = torch.reshape(out, [lengths, batch_size, channels * dims])\n",
        "        out, _ = self.enhance(rnn_in)\n",
        "        out = self.tranform(out)\n",
        "        out = torch.reshape(out, [lengths, batch_size, channels, dims])\n",
        "\n",
        "        out = out.permute(1, 2, 3, 0)\n",
        "\n",
        "        if skip_type:  # use skip connection\n",
        "            for idx in range(len(self.decoder)):\n",
        "                out = torch.cat([out, encoder_out[-1 - idx]], 1)\n",
        "                out = self.decoder[idx](out)\n",
        "                out = out[..., 1:, 1:]  #\n",
        "        else:\n",
        "            for idx in range(len(self.decoder)):\n",
        "                out = self.decoder[idx](out)\n",
        "                out = out[..., 1:]\n",
        "\n",
        "        # mask_mags = F.pad(out, [0, 0, 1, 0])\n",
        "        out = out.squeeze(1)\n",
        "\n",
        "        if direct_mapping:  # spectral mapping\n",
        "            target_mags, _ = self.stft(target)\n",
        "\n",
        "            out_real = out * torch.cos(phase)\n",
        "            out_imag = out * torch.sin(phase)\n",
        "\n",
        "            out_spec = torch.cat([out_real, out_imag], 1)\n",
        "\n",
        "            out_wav = self.istft(out_spec)\n",
        "            out_wav = torch.squeeze(out_wav, 1)\n",
        "            out_wav = torch.clamp_(out_wav, -1, 1)\n",
        "\n",
        "            return out, target_mags, out_wav\n",
        "        else:  # T-F masking\n",
        "            # mask_mags = torch.clamp_(mask_mags,0,100)\n",
        "            mask_mags = torch.tanh(out)\n",
        "            est_mags = mask_mags * mags\n",
        "            out_real = est_mags * torch.cos(phase)\n",
        "            out_imag = est_mags * torch.sin(phase)\n",
        "\n",
        "            out_spec = torch.cat([out_real, out_imag], 1)\n",
        "\n",
        "            out_wav = self.istft(out_spec)\n",
        "            out_wav = torch.squeeze(out_wav, 1)\n",
        "            out_wav = torch.clamp_(out_wav, -1, 1)\n",
        "\n",
        "            return out_wav\n",
        "\n",
        "    def get_params(self, weight_decay=0.0):\n",
        "        # add L2 penalty\n",
        "        weights, biases = [], []\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                biases += [param]\n",
        "            else:\n",
        "                weights += [param]\n",
        "        params = [{\n",
        "            'params': weights,\n",
        "            'weight_decay': weight_decay,\n",
        "        }, {\n",
        "            'params': biases,\n",
        "            'weight_decay': 0.0,\n",
        "        }]\n",
        "        return params\n",
        "\n",
        "    def loss(self, estimated, target):\n",
        "        if current_loss == 'MSE':\n",
        "            return F.mse_loss(estimated, target, reduction='mean')\n",
        "        elif current_loss == 'SDR':\n",
        "            return -sdr(target, estimated)\n",
        "        elif current_loss == 'SI-SNR':\n",
        "            return -(si_snr(estimated, target))\n",
        "        elif current_loss == 'SI-SDR':\n",
        "            return -(si_sdr(target, estimated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDKYZuA-oSgZ"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntb3y33ZoUn3"
      },
      "source": [
        "#######################################################################\n",
        "#                             For train                               #\n",
        "#######################################################################\n",
        "def model_train(model, optimizer, train_loader, DEVICE):\n",
        "    # initialization\n",
        "    train_loss = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    # arr = []\n",
        "    # train\n",
        "    model.train()\n",
        "    for inputs, targets in Bar(train_loader):\n",
        "                batch_num += 1\n",
        "\n",
        "                # to cuda\n",
        "                inputs = inputs.float().to(DEVICE)\n",
        "                targets = targets.float().to(DEVICE)\n",
        "\n",
        "                if direct_mapping:\n",
        "                  output_mag, target_mag, _ = model(inputs, targets)\n",
        "                  loss = model.loss(output_mag, target_mag)\n",
        "                else:\n",
        "                  outputs = model(inputs)\n",
        "                  loss = model.loss(outputs, targets)\n",
        "                # # if you want to check the scale of the loss\n",
        "                # print('loss: {:.4}'.format(loss))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss\n",
        "    train_loss /= batch_num\n",
        "\n",
        "    return train_loss  ##\n",
        "\n",
        "\n",
        "#######################################################################\n",
        "#                           For validation                            #\n",
        "#######################################################################\n",
        "def model_validate(model, validation_loader, dir_to_save, epoch, DEVICE):\n",
        "    # initialization\n",
        "    validation_loss = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    avg_pesq = 0\n",
        "    avg_stoi = 0\n",
        "\n",
        "    all_batch_input = []\n",
        "    all_batch_target = []\n",
        "    all_batch_output = []\n",
        "\n",
        "    # for record the score each samples\n",
        "    f_score = open(dir_to_save + '/Epoch_' + '%d_SCORES' % epoch, 'a')\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "                for inputs, targets in Bar(validation_loader):\n",
        "                    batch_num += 1\n",
        "\n",
        "                    # to cuda\n",
        "                    inputs = inputs.float().to(DEVICE)\n",
        "                    targets = targets.float().to(DEVICE)\n",
        "\n",
        "                    if direct_mapping:\n",
        "                        output_mag, target_mag, outputs = model(inputs, targets, direct_mapping=True)\n",
        "                        loss = model.loss(output_mag, target_mag)\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = model.loss(outputs, targets)\n",
        "\n",
        "                    validation_loss += loss\n",
        "\n",
        "                    # estimate the output speech with pesq and stoi\n",
        "                    estimated_wavs = outputs.cpu().detach().numpy()\n",
        "                    clean_wavs = targets.cpu().detach().numpy()\n",
        "\n",
        "                    pesq = cal_pesq(estimated_wavs, clean_wavs)\n",
        "                    stoi = cal_stoi(estimated_wavs, clean_wavs)\n",
        "\n",
        "                    # pesq: 0.1 better / stoi: 0.01 better\n",
        "                    for i in range(len(pesq)):\n",
        "                        f_score.write('PESQ {:.6f} | STOI {:.6f}\\n'.format(pesq[i], stoi[i]))\n",
        "\n",
        "                    # reshape for sum\n",
        "                    pesq = np.reshape(pesq, (1, -1))\n",
        "                    stoi = np.reshape(stoi, (1, -1))\n",
        "\n",
        "                    avg_pesq += sum(pesq[0]) / len(inputs)\n",
        "                    avg_stoi += sum(stoi[0]) / len(inputs)\n",
        "\n",
        "                validation_loss /= batch_num\n",
        "                avg_pesq /= batch_num\n",
        "                avg_stoi /= batch_num\n",
        "\n",
        "                return validation_loss, avg_pesq, avg_stoi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJZFyj_toVbj"
      },
      "source": [
        "# Train_interface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kicYZcSRoYNy"
      },
      "source": [
        "###############################################################################\n",
        "#                        Helper function definition                           #\n",
        "###############################################################################\n",
        "# Write training related parameters into the log file.\n",
        "def write_status_to_log_file(fp, total_parameters):\n",
        "    fp.write('%d-%d-%d %d:%d:%d\\n' %\n",
        "             (time.localtime().tm_year, time.localtime().tm_mon,\n",
        "              time.localtime().tm_mday, time.localtime().tm_hour,\n",
        "              time.localtime().tm_min, time.localtime().tm_sec))\n",
        "    fp.write('total params   : %d (%.2f M, %.2f MBytes)\\n' %\n",
        "             (total_parameters,\n",
        "              total_parameters / 1000000.0,\n",
        "              total_parameters * 4.0 / 1000000.0))\n",
        "\n",
        "\n",
        "# Calculate the size of total network.\n",
        "def calculate_total_params(our_model):\n",
        "    total_parameters = 0\n",
        "    for variable in our_model.parameters():\n",
        "        shape = variable.size()\n",
        "        variable_parameters = 1\n",
        "        for dim in shape:\n",
        "            variable_parameters *= dim\n",
        "        total_parameters += variable_parameters\n",
        "\n",
        "    return total_parameters\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#         Parameter Initialization and Setting for model training             #\n",
        "###############################################################################\n",
        "# Set device\n",
        "DEVICE = torch.device('cpu' ) # if you want to run the code with 'cpu', change 'cpu'\n",
        "\n",
        "# Set model\n",
        "model = CRN().to(DEVICE)\n",
        "# Set optimizer and learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "total_params = calculate_total_params(model)\n",
        "\n",
        "###############################################################################\n",
        "#                        Confirm model information                            #\n",
        "###############################################################################\n",
        "print('%d-%d-%d %d:%d:%d\\n' %\n",
        "      (time.localtime().tm_year, time.localtime().tm_mon,\n",
        "       time.localtime().tm_mday, time.localtime().tm_hour,\n",
        "       time.localtime().tm_min, time.localtime().tm_sec))\n",
        "print('total params   : %d (%.2f M, %.2f MBytes)\\n' %\n",
        "      (total_params,\n",
        "       total_params / 1000000.0,\n",
        "       total_params * 4.0 / 1000000.0))\n",
        "\n",
        "###############################################################################\n",
        "#                              Create Dataloader                              #\n",
        "###############################################################################\n",
        "train_loader = create_dataloader(mode='train')\n",
        "validation_loader = create_dataloader(mode='valid')\n",
        "\n",
        "###############################################################################\n",
        "#                        Set a log file to store progress.                    #\n",
        "#               Set a hps file to store hyper-parameters information.         #\n",
        "###############################################################################\n",
        "if chkpt_model is not None:  # Load the checkpoint\n",
        "    print('Resuming from checkpoint: %s' % chkpt_path)\n",
        "\n",
        "    # Set a log file to store progress.\n",
        "    dir_to_save = job_dir + chkpt_model\n",
        "\n",
        "    checkpoint = torch.load(chkpt_path)\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    epoch_start_idx = checkpoint['epoch'] + 1\n",
        "    mse_vali_total = np.load(str(dir_to_save + '/mse_vali_total.npy'))\n",
        "else:  # First learning\n",
        "    print('Starting new training run...')\n",
        "    epoch_start_idx = 1\n",
        "    mse_vali_total = np.zeros(max_epochs)\n",
        "\n",
        "    # Set a log file to store progress.\n",
        "    dir_to_save = job_dir + expr_num + '_%d.%d' % (time.localtime().tm_mon,\n",
        "                                                           time.localtime().tm_mday) + '_%s' % current_model + '_%s' % current_loss\n",
        "\n",
        "# make the file directory\n",
        "if not os.path.exists(dir_to_save):\n",
        "    os.mkdir(dir_to_save)\n",
        "\n",
        "# logging\n",
        "log_fname = str(dir_to_save + '/log.txt')\n",
        "fp = open(log_fname, 'w')\n",
        "write_status_to_log_file(fp, total_params)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "#                             Main program start !!                           #\n",
        "###############################################################################\n",
        "###############################################################################\n",
        "\n",
        "###############################################################################\n",
        "#                                    Train                                    #\n",
        "###############################################################################\n",
        "for epoch in range(epoch_start_idx, max_epochs):\n",
        "        start_time = time.time()\n",
        "        # Training\n",
        "        train_loss = model_train(model, optimizer, train_loader, DEVICE)\n",
        "\n",
        "        # save checkpoint file to resume training\n",
        "        save_path = str(dir_to_save + '/' + ('chkpt_%d.pt' % epoch))\n",
        "        torch.save({\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'epoch': epoch\n",
        "        }, save_path)\n",
        "\n",
        "        # Validation\n",
        "        vali_loss, vali_pesq, vali_stoi = \\\n",
        "        model_validate(model, validation_loader, dir_to_save, epoch, DEVICE)\n",
        "\n",
        "        print('Epoch [{}] | T {:.6f} | V {:.6} takes {:.2f} seconds\\n'\n",
        "                  .format(epoch, train_loss, vali_loss, time.time() - start_time))\n",
        "        print('          | V PESQ: {:.6f} | STOI: {:.6f} '.format(vali_pesq, vali_stoi))\n",
        "        # log file save\n",
        "        fp.write('Epoch [{}] | T {:.6f} | V {:.6} takes {:.2f} seconds\\n'\n",
        "                     .format(epoch, train_loss, vali_loss, time.time() - start_time))\n",
        "        fp.write('          | V PESQ: {:.6f} | STOI: {:.6f} \\n'.format(vali_pesq, vali_stoi))\n",
        "\n",
        "        mse_vali_total[epoch - 1] = vali_loss\n",
        "        np.save(str(dir_to_save + '/mse_vali_total.npy'), mse_vali_total)\n",
        "\n",
        "\n",
        "fp.close()\n",
        "print('Training has been finished.')\n",
        "\n",
        "# Copy optimum model that has minimum MSE.\n",
        "print('Save optimum models...')\n",
        "min_index = np.argmin(mse_vali_total)\n",
        "print('Minimum validation loss is at ' + str(min_index + 1) + '.')\n",
        "src_file = str(dir_to_save + '/' + ('chkpt_%d.pt' % (min_index + 1)))\n",
        "tgt_file = str(dir_to_save + '/chkpt_opt.pt')\n",
        "shutil.copy(src_file, tgt_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
